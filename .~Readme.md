**Known Issues**
(my list of changes I would make if I had more time)

- Would not store image binaries in the db
  - I also think images coming in via a json put/post would need to be base64 encoded with would have the effect of increasing the actual file size, not an issue on upload I don’t think but we’d need to take this into account when moving to S3Would implement token authentication and not leave the API wide open
- Would constrain the API endpoints to only those supported (including the HTTP methods)
- Would probably use celery instead of django-background-tasks but requires more setup
- Would use something more robust than cron for managing the background process (like supervisor)
- Would not hardcode the throttling variables but would make them easily accessible “settings” in the code -- throttling is currently dependent the throttle threads sleep time and number of images processed per throttle period
- Would add logging/monitoring to make sure upload process was working as expected, backlog wasn’t getting too big, looking for consistent upload failures
- Would actually implement s3 uploads using the django-storages lib - note I installed this in the requirements.txt but spent some time researching and realized stubbing it out would take just as much time as just doing it
- Completely missing test coverage!
- Since I wasn’t able to really test this at all I have some concerns that this would actually be too slow instead of too fast and we could end up with an infinite backlog of images to upload - I’d want to do some testing to actually watch how long things were taking and find ways to adjust if necessary

**Known Bugs**

- There appears to be a bug in the background tasks lib that was failing to start the background task processing at app startups so my instructions below include starting it by hand

**Setup and "testing"**

- Clone the github repo

- cd in to the root directory 

- run "docker-compose up"

- In a separate terminal run "docker-compose run web bash"

- In the terminal run "python manage.py shell"

- Once on the django shell we'll first verify there are 5000 dummy images in the system, then we'll start the background uploading by calling upload_images() - this only needs to be called once and will now presumable run indefinitely 

  ```
  >>> from api.models import Image
  >>> Image.objects.all().count()
  5000
  >>> from api.tasks import upload_images
  >>> upload_images(repeat=60,repeat_until=None)
  ```



The api is also now available at localhost:8000